# Learning Notebooks

> **Educational materials covering LLM concepts from fundamentals to advanced topics**

This directory contains hands-on Jupyter notebooks that build understanding of Large Language Models from the ground up. Each notebook includes implementations, explanations, and practical examples.

## ğŸ“– Recommended Learning Path

```
01-Fundamentals â†’ 02-Architectures â†’ 03-Inference â†’ 04-Evaluation â†’ 05-Advanced
```

Work through sections sequentially for best comprehension, or jump to specific topics as needed.

---

## ğŸ“š Sections

### [01 - Fundamentals](./01-fundamentals/)
**Core building blocks of LLMs**

- **Tokenization**: BPE algorithm, vocabulary building, encoding/decoding
- **Embeddings**: Skip-gram, Word2Vec, sentence transformers
- **Normalization**: Layer normalization vs batch normalization

**Prerequisites**: Basic Python, linear algebra  
**Time**: ~3-4 hours

---

### [02 - Architectures](./02-architectures/)
**Transformer components and optimizations**

- **Attention Mechanisms**: Self-attention, multi-head attention, cross-attention, masking  
- **Positional Encoding**: How transformers handle sequence order
- **Optimizations**: LoRA (Low-Rank Adaptation), FlashAttention

**Prerequisites**: 01-Fundamentals, matrix operations  
**Time**: ~5-6 hours

---

### [03 - Inference Techniques](./03-inference-techniques/)
**Generation strategies and prompting**

- **Beam Search**: Sequence generation beyond greedy decoding
- **Chain-of-Thought**: Step-by-step reasoning prompting
- **Synthetic Data**: Techniques for data augmentation

**Prerequisites**: Understanding of LLM basics  
**Time**: ~2-3 hours

---

### [04 - Evaluation](./04-evaluation/)
**Measuring model performance**

- **Evaluation Techniques**: Perplexity, BLEU, ROUGE, F1, task-specific metrics
- **Elo Rating System**: Pairwise model comparison

**Prerequisites**: Basic statistics  
**Time**: ~2 hours

---

### [05 - Advanced Concepts](./05-advanced-concepts/)
**Specialized topics**

- **Diffusion Models**: Generative modeling fundamentals

**Prerequisites**: Strong understanding of neural networks  
**Time**: ~3-4 hours

---

## ğŸ¯ How to Use These Notebooks

### For Learning:
1. Start at [01-Fundamentals](./01-fundamentals/) if new to LLMs
2. Read code + explanations carefully
3. Run cells and experiment with parameters
4. Try modifying implementations
5. Reference [showcase projects](../projects/) to see concepts in production

### For Reference:
- Jump to specific topics as needed
- Use as implementation templates
- Compare with your own approaches

### For Interviews:
- Review implementations before technical discussions
- Understand trade-offs (e.g., why LoRA vs full fine-tuning)
- Practice explaining concepts clearly

---

## ğŸ”— Connections to Showcase Projects

| Notebook Topic | Related Project | Application |
|----------------|-----------------|-------------|
| Tokenization | All projects | Input processing |
| Embeddings | Semantic Search, RAG | Document retrieval |
| Attention | All projects | Understanding transformers |
| Few-Shot (resources/) | Matching, RAG | Prompt engineering |
| Evaluation | All projects | Quality metrics |

---

## ğŸ“‚ Quick Navigation

```
notebooks/
â”œâ”€â”€ 01-fundamentals/
â”‚   â”œâ”€â”€ tokenization/
â”‚   â”‚   â”œâ”€â”€ Tokenization.ipynb
â”‚   â”‚   â””â”€â”€ tokenizer_model/
â”‚   â”œâ”€â”€ embeddings/
â”‚   â”‚   â””â”€â”€ Embeddings.ipynb
â”‚   â””â”€â”€ normalization/
â”‚       â””â”€â”€ Layer_vs_batch_norm.ipynb
â”œâ”€â”€ 02-architectures/
â”‚   â”œâ”€â”€ attention/
â”‚   â”‚   â”œâ”€â”€ single_vs_multihead_SelfAttention.ipynb
â”‚   â”‚   â”œâ”€â”€ cross-attention.ipynb
â”‚   â”‚   â”œâ”€â”€ masking.ipynb
â”‚   â”‚   â””â”€â”€ FlashAttention_implementation.ipynb
â”‚   â”œâ”€â”€ positional-encoding/
â”‚   â”‚   â””â”€â”€ positional_encoding.ipynb
â”‚   â””â”€â”€ optimizations/
â”‚       â””â”€â”€ lora_forwardPass.ipynb
â”œâ”€â”€ 03-inference-techniques/
â”‚   â”œâ”€â”€ BeamSearch.ipynb
â”‚   â”œâ”€â”€ ChainOfThought.ipynb
â”‚   â””â”€â”€ Synthetic_Techniques.ipynb
â”œâ”€â”€ 04-evaluation/
â”‚   â”œâ”€â”€ Evaluation_techniques.ipynb
â”‚   â””â”€â”€ Elo_rating_system.ipynb
â””â”€â”€ 05-advanced-concepts/
    â””â”€â”€ diffusion/
        â””â”€â”€ Diffusion_models.ipynb
```

---

## ğŸ’¡ Tips

- **Jupyter Setup**: Install with `pip install jupyter` if needed
- **Dependencies**: Most notebooks have minimal requirements (numpy, matplotlib)
- **Runtime**: Use GPU for diffusion models if available
- **Modifications**: Feel free to experiment! Change hyperparameters, try different datasets

---

[â† Back to Main Portfolio](../) | [View Showcase Projects](../projects/)
